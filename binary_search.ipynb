{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import datasets\n",
    "import threading\n",
    "import pydub\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"CAiRE/ASCEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         id                                               path  \\\n0     00000  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n1     00001  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n2     00002  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n3     00003  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n4     00004  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n...     ...                                                ...   \n9864  09864  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n9865  09865  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n9866  09866  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n9867  09867  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n9868  09868  C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...   \n\n                                                  audio  \\\n0     {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n1     {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n2     {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n3     {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n4     {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n...                                                 ...   \n9864  {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n9865  {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n9866  {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n9867  {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n9868  {'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...   \n\n                                          transcription  duration language  \\\n0                                           我刚刚开始record     1.560    mixed   \n1                                         嗯hello我的名字叫徐妍     4.160    mixed   \n2                                嗯初次见面nice to meet you嗯     3.320    mixed   \n3                       今天呢我非常希望能够通过这个机会去跟你make friends     5.700    mixed   \n4                                                嗯你知道就是     2.020       zh   \n...                                                 ...       ...      ...   \n9864                                                  嗯     0.550       zh   \n9865                              her intellect intelli     1.485       en   \n9866  学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...    14.506    mixed   \n9867  home school education can provide an environme...     8.611       en   \n9868                                        home school     0.399       en   \n\n      original_speaker_id  session_id       topic  \n0                       1           1     persona  \n1                       1           1     persona  \n2                       1           1     persona  \n3                       1           1     persona  \n4                       1           1     persona  \n...                   ...         ...         ...  \n9864                    8           4  technology  \n9865                    8           3   education  \n9866                    8           3   education  \n9867                    8           3   education  \n9868                    8           3   education  \n\n[9869 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>path</th>\n      <th>audio</th>\n      <th>transcription</th>\n      <th>duration</th>\n      <th>language</th>\n      <th>original_speaker_id</th>\n      <th>session_id</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>我刚刚开始record</td>\n      <td>1.560</td>\n      <td>mixed</td>\n      <td>1</td>\n      <td>1</td>\n      <td>persona</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00001</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>嗯hello我的名字叫徐妍</td>\n      <td>4.160</td>\n      <td>mixed</td>\n      <td>1</td>\n      <td>1</td>\n      <td>persona</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00002</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>嗯初次见面nice to meet you嗯</td>\n      <td>3.320</td>\n      <td>mixed</td>\n      <td>1</td>\n      <td>1</td>\n      <td>persona</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00003</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>今天呢我非常希望能够通过这个机会去跟你make friends</td>\n      <td>5.700</td>\n      <td>mixed</td>\n      <td>1</td>\n      <td>1</td>\n      <td>persona</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00004</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>嗯你知道就是</td>\n      <td>2.020</td>\n      <td>zh</td>\n      <td>1</td>\n      <td>1</td>\n      <td>persona</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9864</th>\n      <td>09864</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>嗯</td>\n      <td>0.550</td>\n      <td>zh</td>\n      <td>8</td>\n      <td>4</td>\n      <td>technology</td>\n    </tr>\n    <tr>\n      <th>9865</th>\n      <td>09865</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>her intellect intelli</td>\n      <td>1.485</td>\n      <td>en</td>\n      <td>8</td>\n      <td>3</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>9866</th>\n      <td>09866</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...</td>\n      <td>14.506</td>\n      <td>mixed</td>\n      <td>8</td>\n      <td>3</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>9867</th>\n      <td>09867</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>home school education can provide an environme...</td>\n      <td>8.611</td>\n      <td>en</td>\n      <td>8</td>\n      <td>3</td>\n      <td>education</td>\n    </tr>\n    <tr>\n      <th>9868</th>\n      <td>09868</td>\n      <td>C:\\Users\\Owner\\.cache\\huggingface\\datasets\\dow...</td>\n      <td>{'path': 'C:\\Users\\Owner\\.cache\\huggingface\\da...</td>\n      <td>home school</td>\n      <td>0.399</td>\n      <td>en</td>\n      <td>8</td>\n      <td>3</td>\n      <td>education</td>\n    </tr>\n  </tbody>\n</table>\n<p>9869 rows × 9 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to separate mp3 file by timestamp\n",
    "set = pd.DataFrame(dataset['train'])\n",
    "display(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Owner\\.cache\\huggingface\\datasets\\downloads\\extracted\\bb19ffdd43a09a30bc7580ba3c1fbbdaae5c86c6fca95346cc7ea64d036e35d1\\waves/ses4_spk26_L24529_475.700_8.140.wav\n"
     ]
    }
   ],
   "source": [
    "path = set.at[9595, 'path']\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    path = set.at[i, 'path']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def split_audio(file, start, end):\n",
    "    wav = AudioSegment.from_wav(file)\n",
    "    first_half = wav[start:end]\n",
    "    second_half = wav[end:]\n",
    "    first_half.export(\"first_half_\"+file, format=\"wav\")\n",
    "    second_half.export(\"second_half_\"+file, format=\"wav\")\n",
    "\n",
    "def get_highest_hi_en(file):\n",
    "    audio = whisper.load_audio(file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_probs = [{'key': key, 'value': value} for key, value in sorted_probs]\n",
    "    hi_prob = probs['hi']\n",
    "    en_prob = probs['en']\n",
    "    if hi_prob > en_prob:\n",
    "        return {'key': 'hi','value': probs['hi']}\n",
    "    else:\n",
    "        return {'key': 'en', 'value': probs['en']}\n",
    "\n",
    "def get_highest_whisper_entry(file):\n",
    "    audio = whisper.load_audio(file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_probs = [{'key': key, 'value': value} for key, value in sorted_probs]\n",
    "    return sorted_probs[0]\n",
    "\n",
    "def binary_search(file, start, end, new_file, my_dict):\n",
    "    if get_highest_hi_en(new_file)['value'] > 0.6:\n",
    "        my_dict[start] = get_highest_hi_en(new_file)['key']\n",
    "        print('high prob of', get_highest_hi_en(new_file)['value'] ,'that its 1 language:', my_dict)\n",
    "        return my_dict\n",
    "    \n",
    "    if end - start <= 2000:\n",
    "        my_dict[start] = get_highest_hi_en(new_file)['key']\n",
    "        print('clip too short, split with prob:', get_highest_hi_en(new_file)['value'], my_dict)\n",
    "        return\n",
    "    \n",
    "    split_position = start + np.ceil((end - start) / 2)\n",
    "    split_position = int(split_position)\n",
    "    split_audio(file, start, split_position)\n",
    "    binary_search(file, start, split_position, \"first_half_\"+file, my_dict)\n",
    "    \n",
    "    # Update split position for the second half\n",
    "    split_position = int(split_position)\n",
    "    split_audio(file, split_position, end)\n",
    "    binary_search(file, split_position, end, \"second_half_\"+file, my_dict)\n",
    "\n",
    "    return my_dict\n",
    "\n",
    "results = []\n",
    "\n",
    "def chunk_audio_30_sec(file):\n",
    "    files = []\n",
    "    wav_file = AudioSegment.from_wav(file)\n",
    "    duration = len(wav_file)\n",
    "    for i in range(0, duration, 30000):\n",
    "        chunk = wav_file[i:i+29999]\n",
    "        name = f\"{int(i/30000)}.wav\"\n",
    "        chunk.export(name, format=\"wav\")\n",
    "        files.append(name)\n",
    "    return files\n",
    "\n",
    "def get_whisper_translation(translated_texts, audio, curr_language):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    options = whisper.DecodingOptions(language=curr_language, task='translate', fp16=False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    translated_texts.append(result.text)    \n",
    "\n",
    "def translate_audio(audio_path, segments_dict, model_name=\"base\"):\n",
    "    model = whisper.load_model(model_name)\n",
    "    full_audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
    "\n",
    "    translated_texts = []\n",
    "    start_time = 0  # Start of the first segment\n",
    "    current_language = list(segments_dict.values())[0]  # Language of the first segment\n",
    "\n",
    "    for end_time, language in segments_dict.items():\n",
    "        if language != current_language:\n",
    "            # Process the accumulated segment in the current language\n",
    "            start_ms = start_time\n",
    "            end_ms = end_time - 1  # Adjusting to include the last moment of the previous language\n",
    "\n",
    "            audio_segment = full_audio[start_ms:end_ms]\n",
    "            temp_file = \"temp_segment.wav\"\n",
    "            audio_segment.export(temp_file, format=\"wav\")\n",
    "\n",
    "            audio = whisper.load_audio(temp_file)\n",
    "            get_whisper_translation(translated_texts, audio, current_language)\n",
    "\n",
    "            os.remove(temp_file)\n",
    "\n",
    "            # Update the start time and current language\n",
    "            start_time = end_time\n",
    "            current_language = language\n",
    "\n",
    "    # Process the final segment\n",
    "    start_ms = start_time\n",
    "    end_ms = len(full_audio)  # Till the end of the adio\n",
    "    audio_segment = full_audio[start_ms:end_ms]\n",
    "    temp_file = \"temp_segment.wav\"\n",
    "    audio_segment.export(temp_file, format=\"wav\")\n",
    "    audio = whisper.load_audio(temp_file)\n",
    "    get_whisper_translation(translated_texts, audio, current_language)\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    full_translation = ' '.join(translated_texts)\n",
    "    return full_translation\n",
    "\n",
    "my_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m chunk_audio_30_sec(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcombined_audio.wav\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mbinary_search\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1.wav\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mAudioSegment\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_wav\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1.wav\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m1.wav\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmy_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m translate_audio(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1.wav\u001B[39m\u001B[38;5;124m\"\u001B[39m, my_dict)\n",
      "Cell \u001B[1;32mIn[26], line 34\u001B[0m, in \u001B[0;36mbinary_search\u001B[1;34m(file, start, end, new_file, my_dict)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbinary_search\u001B[39m(file, start, end, new_file, my_dict):\n\u001B[1;32m---> 34\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mget_highest_hi_en\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnew_file\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0.6\u001B[39m:\n\u001B[0;32m     35\u001B[0m         my_dict[start] \u001B[38;5;241m=\u001B[39m get_highest_hi_en(new_file)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     36\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhigh prob of\u001B[39m\u001B[38;5;124m'\u001B[39m, get_highest_hi_en(new_file)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m] ,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthat its 1 language:\u001B[39m\u001B[38;5;124m'\u001B[39m, my_dict)\n",
      "Cell \u001B[1;32mIn[26], line 14\u001B[0m, in \u001B[0;36mget_highest_hi_en\u001B[1;34m(file)\u001B[0m\n\u001B[0;32m     12\u001B[0m audio \u001B[38;5;241m=\u001B[39m whisper\u001B[38;5;241m.\u001B[39mpad_or_trim(audio)\n\u001B[0;32m     13\u001B[0m mel \u001B[38;5;241m=\u001B[39m whisper\u001B[38;5;241m.\u001B[39mlog_mel_spectrogram(audio)\u001B[38;5;241m.\u001B[39mto(model\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 14\u001B[0m _, probs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetect_language\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     15\u001B[0m sorted_probs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(probs\u001B[38;5;241m.\u001B[39mitems(), key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[38;5;241m1\u001B[39m], reverse\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     16\u001B[0m sorted_probs \u001B[38;5;241m=\u001B[39m [{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkey\u001B[39m\u001B[38;5;124m'\u001B[39m: key, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m'\u001B[39m: value} \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m sorted_probs]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\decoding.py:52\u001B[0m, in \u001B[0;36mdetect_language\u001B[1;34m(model, mel, tokenizer)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# skip encoder forward pass if already-encoded audio features were given\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mel\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m:] \u001B[38;5;241m!=\u001B[39m (model\u001B[38;5;241m.\u001B[39mdims\u001B[38;5;241m.\u001B[39mn_audio_ctx, model\u001B[38;5;241m.\u001B[39mdims\u001B[38;5;241m.\u001B[39mn_audio_state):\n\u001B[1;32m---> 52\u001B[0m     mel \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m# forward pass using a single token, startoftranscript\u001B[39;00m\n\u001B[0;32m     55\u001B[0m n_audio \u001B[38;5;241m=\u001B[39m mel\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:170\u001B[0m, in \u001B[0;36mAudioEncoder.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    167\u001B[0m x \u001B[38;5;241m=\u001B[39m (x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositional_embedding)\u001B[38;5;241m.\u001B[39mto(x\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m    169\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m block \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks:\n\u001B[1;32m--> 170\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    172\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_post(x)\n\u001B[0;32m    173\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:139\u001B[0m, in \u001B[0;36mResidualAttentionBlock.forward\u001B[1;34m(self, x, xa, mask, kv_cache)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcross_attn:\n\u001B[0;32m    138\u001B[0m     x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcross_attn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcross_attn_ln(x), xa, kv_cache\u001B[38;5;241m=\u001B[39mkv_cache)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m--> 139\u001B[0m x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmlp_ln\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\whisper\\model.py:37\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m---> 37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "chunk_audio_30_sec('combined_audio.wav')\n",
    "binary_search(\"1.wav\", 0, len(AudioSegment.from_wav(\"1.wav\")), \"1.wav\", my_dict)\n",
    "translate_audio(\"1.wav\", my_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip too short, split with prob: 0.4205993711948395 {0: 'en'}\n",
      "high prob of 0.7981908321380615 that its 1 language: {0: 'en', 1875: 'hi'}\n",
      "high prob of 0.8285928964614868 that its 1 language: {0: 'en', 1875: 'hi', 3750: 'hi'}\n",
      "high prob of 0.7813481688499451 that its 1 language: {0: 'en', 1875: 'hi', 3750: 'hi', 7500: 'hi'}\n",
      "high prob of 0.9189804792404175 that its 1 language: {0: 'en', 1875: 'hi', 3750: 'hi', 7500: 'hi', 15000: 'hi'}\n",
      "high prob of 0.8299621343612671 that its 1 language: {0: 'en', 1875: 'hi', 3750: 'hi', 7500: 'hi', 15000: 'hi', 22500: 'hi'}\n",
      "high prob of 0.9538677930831909 that its 1 language: {0: 'en', 1875: 'hi', 3750: 'hi', 7500: 'hi', 15000: 'hi', 22500: 'hi', 26250: 'hi'}\n",
      "clip too short, split with prob: 0.3625158965587616 {0: 'en', 1875: 'hi', 3750: 'hi', 7500: 'hi', 15000: 'hi', 22500: 'hi', 26250: 'hi', 28125: 'en'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "\"of the investment that I have been making. If you want to make something 4 years from a 2 year old age, it means that you want to make a major difference. So when it's actually living your life, I think there are no complaints. Which is what is happening with me right now. I always wanted to make an actress, I made a film, I didn't know what was going on at that time. I just realized that...\""
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_search(\"alia_30s_clip_2.wav\", 0, len(AudioSegment.from_wav(\"alia_30s_clip_2.wav\")), \"alia_30s_clip_2.wav\", my_dict)\n",
    "translate_audio(\"alia_30s_clip_2.wav\", my_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
