{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import datasets\n",
    "import threading\n",
    "import pydub\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import whisper\n",
    "from pydub import AudioSegment\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"CAiRE/ASCEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>audio</th>\n",
       "      <th>transcription</th>\n",
       "      <th>duration</th>\n",
       "      <th>language</th>\n",
       "      <th>original_speaker_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>我刚刚开始record</td>\n",
       "      <td>1.560</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>嗯hello我的名字叫徐妍</td>\n",
       "      <td>4.160</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>嗯初次见面nice to meet you嗯</td>\n",
       "      <td>3.320</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>今天呢我非常希望能够通过这个机会去跟你make friends</td>\n",
       "      <td>5.700</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>嗯你知道就是</td>\n",
       "      <td>2.020</td>\n",
       "      <td>zh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>09864</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>嗯</td>\n",
       "      <td>0.550</td>\n",
       "      <td>zh</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>09865</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>her intellect intelli</td>\n",
       "      <td>1.485</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>09866</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...</td>\n",
       "      <td>14.506</td>\n",
       "      <td>mixed</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>09867</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>home school education can provide an environme...</td>\n",
       "      <td>8.611</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>09868</td>\n",
       "      <td>C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...</td>\n",
       "      <td>{'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...</td>\n",
       "      <td>home school</td>\n",
       "      <td>0.399</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9869 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               path  \\\n",
       "0     00000  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "1     00001  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "2     00002  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "3     00003  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "4     00004  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "...     ...                                                ...   \n",
       "9864  09864  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "9865  09865  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "9866  09866  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "9867  09867  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "9868  09868  C:\\Users\\saleh\\.cache\\huggingface\\datasets\\dow...   \n",
       "\n",
       "                                                  audio  \\\n",
       "0     {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "1     {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "2     {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "3     {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "4     {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "...                                                 ...   \n",
       "9864  {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "9865  {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "9866  {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "9867  {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "9868  {'path': 'C:\\Users\\saleh\\.cache\\huggingface\\da...   \n",
       "\n",
       "                                          transcription  duration language  \\\n",
       "0                                           我刚刚开始record     1.560    mixed   \n",
       "1                                         嗯hello我的名字叫徐妍     4.160    mixed   \n",
       "2                                嗯初次见面nice to meet you嗯     3.320    mixed   \n",
       "3                       今天呢我非常希望能够通过这个机会去跟你make friends     5.700    mixed   \n",
       "4                                                嗯你知道就是     2.020       zh   \n",
       "...                                                 ...       ...      ...   \n",
       "9864                                                  嗯     0.550       zh   \n",
       "9865                              her intellect intelli     1.485       en   \n",
       "9866  学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...    14.506    mixed   \n",
       "9867  home school education can provide an environme...     8.611       en   \n",
       "9868                                        home school     0.399       en   \n",
       "\n",
       "      original_speaker_id  session_id       topic  \n",
       "0                       1           1     persona  \n",
       "1                       1           1     persona  \n",
       "2                       1           1     persona  \n",
       "3                       1           1     persona  \n",
       "4                       1           1     persona  \n",
       "...                   ...         ...         ...  \n",
       "9864                    8           4  technology  \n",
       "9865                    8           3   education  \n",
       "9866                    8           3   education  \n",
       "9867                    8           3   education  \n",
       "9868                    8           3   education  \n",
       "\n",
       "[9869 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to separate mp3 file by timestamp\n",
    "set = pd.DataFrame(dataset['train'])\n",
    "display(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saleh\\.cache\\huggingface\\datasets\\downloads\\extracted\\f7ac516b8b52e26639eabec77d98278b293cb5a5579773126b8901eb92fb8307\\waves/ses4_spk26_L24529_475.700_8.140.wav\n"
     ]
    }
   ],
   "source": [
    "path = set.at[9595, 'path']\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    path = set.at[i, 'path']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='full_alia.wav'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"Alia_Bhatt_Interview_For_Film_Shandaar.mp3\"\n",
    "audio = AudioSegment.from_mp3(path)\n",
    "audio.export(\"full_alia.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high prob of 0.6283053159713745 that its 1 language: {0: 'hi'}\n",
      "clip too short, split with prob: 0.07496034353971481 {0: 'hi', 15000: 'en'}\n",
      "clip too short, split with prob: 0.4506291151046753 {0: 'hi', 15000: 'en', 16875: 'hi'}\n",
      "clip too short, split with prob: 0.0813167467713356 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en'}\n",
      "clip too short, split with prob: 0.5608551502227783 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en', 20625: 'hi'}\n",
      "clip too short, split with prob: 0.5360254049301147 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en', 20625: 'hi', 22500: 'hi'}\n",
      "clip too short, split with prob: 0.2866332530975342 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en', 20625: 'hi', 22500: 'hi', 24375: 'hi'}\n",
      "clip too short, split with prob: 0.20663239061832428 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en', 20625: 'hi', 22500: 'hi', 24375: 'hi', 26250: 'hi'}\n",
      "clip too short, split with prob: 0.3625158965587616 {0: 'hi', 15000: 'en', 16875: 'hi', 18750: 'en', 20625: 'hi', 22500: 'hi', 24375: 'hi', 26250: 'hi', 28125: 'en'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm going to go to church. That will be the next year. I'm here to invite you because it's been a long time. I'm going to see you later. Yes. After this, Kapoor Ancels will be released after Shandar. After that, Upta will be released and after that, he will see. I am not saying anything. What do I say? You have never done anything in your life. Have you ever put your hands on your fav? Yes. Have you ever put your hands on your fav? Have you ever put your hands on your fav? Yes. After that...\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"full_alia.wav\"\n",
    "name = \"full_alia.wav\"\n",
    "total_wav = AudioSegment.from_wav(path)\n",
    "total_wav_file = total_wav.export(name, format=\"wav\")\n",
    "duration = len(total_wav)\n",
    "model = whisper.load_model(\"base\")\n",
    "\n",
    "def split_audio(file, start, end):\n",
    "    wav = AudioSegment.from_wav(file)\n",
    "    first_half = wav[start:end]\n",
    "    second_half = wav[end:]\n",
    "    first_half.export(\"first_half_\"+file, format=\"wav\")\n",
    "    second_half.export(\"second_half_\"+file, format=\"wav\")\n",
    "\n",
    "def get_highest_hi_en(file):\n",
    "    audio = whisper.load_audio(file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_probs = [{'key': key, 'value': value} for key, value in sorted_probs]\n",
    "    hi_prob = probs['hi']\n",
    "    en_prob = probs['en']\n",
    "    if hi_prob > en_prob:\n",
    "        return {'key': 'hi','value': probs['hi']}\n",
    "    else:\n",
    "        return {'key': 'en', 'value': probs['en']}\n",
    "\n",
    "def get_highest_whisper_entry(file):\n",
    "    audio = whisper.load_audio(file)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_probs = [{'key': key, 'value': value} for key, value in sorted_probs]\n",
    "    return sorted_probs[0]\n",
    "\n",
    "def binary_search(file, start, end, new_file, my_dict):\n",
    "    if get_highest_hi_en(new_file)['value'] > 0.6:\n",
    "        my_dict[start] = get_highest_hi_en(new_file)['key']\n",
    "        print('high prob of', get_highest_hi_en(new_file)['value'] ,'that its 1 language:', my_dict)\n",
    "        return my_dict\n",
    "    \n",
    "    if end - start <= 2000:\n",
    "        my_dict[start] = get_highest_hi_en(new_file)['key']\n",
    "        print('clip too short, split with prob:', get_highest_hi_en(new_file)['value'], my_dict)\n",
    "        return\n",
    "    \n",
    "    split_position = start + np.ceil((end - start) / 2)\n",
    "    split_position = int(split_position)\n",
    "    split_audio(file, start, split_position)\n",
    "    binary_search(file, start, split_position, \"first_half_\"+file, my_dict)\n",
    "    \n",
    "    # Update split position for the second half\n",
    "    split_position = int(split_position)\n",
    "    split_audio(file, split_position, end)\n",
    "    binary_search(file, split_position, end, \"second_half_\"+file, my_dict)\n",
    "\n",
    "    return my_dict\n",
    "\n",
    "results = []\n",
    "\n",
    "def chunk_audio_30_sec(file):\n",
    "    files = []\n",
    "    wav_file = AudioSegment.from_wav(file)\n",
    "    duration = len(wav_file)\n",
    "    for i in range(0, duration, 30000):\n",
    "        chunk = wav_file[i:i+29999]\n",
    "        name = f\"{int(i/30000)}.wav\"\n",
    "        chunk.export(name, format=\"wav\")\n",
    "        files.append(name)\n",
    "    return files\n",
    "\n",
    "def get_whisper_translation(translated_texts, audio, curr_language):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    options = whisper.DecodingOptions(language=curr_language, task='translate', fp16=False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    translated_texts.append(result.text)    \n",
    "\n",
    "def translate_audio(audio_path, segments_dict):\n",
    "    full_audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
    "    \n",
    "    translated_texts = []\n",
    "    start_time = 0  # Start of the first segment\n",
    "    current_language = list(segments_dict.values())[0]  # Language of the first segment\n",
    "\n",
    "    threads = []\n",
    "    for end_time, language in segments_dict.items():\n",
    "        if language != current_language:\n",
    "            # Process the accumulated segment in the current language\n",
    "            start_ms = start_time\n",
    "            end_ms = end_time - 1  # Adjusting to include the last moment of the previous language\n",
    "\n",
    "            audio_segment = full_audio[start_ms:end_ms]\n",
    "            temp_file = \"temp_segment.wav\"\n",
    "            audio_segment.export(temp_file, format=\"wav\")\n",
    "            \n",
    "            audio = whisper.load_audio(temp_file)\n",
    "            thread = threading.Thread(target=get_whisper_translation, args=(translated_texts, audio, current_language))\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "            \n",
    "            os.remove(temp_file)\n",
    "\n",
    "            # Update the start time and current language\n",
    "            \n",
    "            start_time = end_time\n",
    "            current_language = language\n",
    "\n",
    "    # Process the final segment\n",
    "    start_ms = start_time\n",
    "    end_ms = len(full_audio)  # Till the end of the audio\n",
    "    audio_segment = full_audio[start_ms:end_ms]\n",
    "    temp_file = \"temp_segment.wav\"\n",
    "    audio_segment.export(temp_file, format=\"wav\")\n",
    "    audio = whisper.load_audio(temp_file)\n",
    "    \n",
    "    thread = threading.Thread(target=get_whisper_translation, args=(translated_texts, audio, current_language))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "    os.remove(temp_file)\n",
    "\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "\n",
    "    full_translation = ' '.join(translated_texts)\n",
    "    return full_translation\n",
    "\n",
    "my_dict = {}\n",
    "\n",
    "chunk_audio_30_sec(name)\n",
    "binary_search(\"12.wav\", 0, len(AudioSegment.from_wav(\"12.wav\")), \"12.wav\", my_dict)\n",
    "translate_audio(\"12.wav\", my_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
