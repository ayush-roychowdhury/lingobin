{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datasets\n",
    "import soundfile\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import pydub\n",
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"pip3 install pydub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5014733a4745c68375a77e2ad3c73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d7014db1f0b4e8e9747b17ff719cc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/930M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b145f33480d84f4e8c2293b8e2207ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5caaf20489304a1db697a125c3ea9732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gauravbelani/.cache/huggingface/datasets/downloads/c0c90a40ffbbe502bf0aa0911c0e2f2afd3837249582355c0b3f798364d8f766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a33fb9f70c447ecae6dee932108b196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gauravbelani/.cache/huggingface/datasets/downloads/e0245f18a1c0d6208d163a72d77fa3b36dd8082671e3acb1bd0a6436501777b3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73ac3d67f2441098e4a2ba769316ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gauravbelani/.cache/huggingface/datasets/downloads/82d074c3031ceb89eb3ee2f120e92edd4eb64530261da4b1ee8a04b10aef0928\n"
     ]
    }
   ],
   "source": [
    "ds = datasets.load_dataset(\"CAiRE/ASCEND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>audio</th>\n",
       "      <th>transcription</th>\n",
       "      <th>duration</th>\n",
       "      <th>language</th>\n",
       "      <th>original_speaker_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>我刚刚开始record</td>\n",
       "      <td>1.560</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>嗯hello我的名字叫徐妍</td>\n",
       "      <td>4.160</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>嗯初次见面nice to meet you嗯</td>\n",
       "      <td>3.320</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>今天呢我非常希望能够通过这个机会去跟你make friends</td>\n",
       "      <td>5.700</td>\n",
       "      <td>mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>嗯你知道就是</td>\n",
       "      <td>2.020</td>\n",
       "      <td>zh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>persona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9864</th>\n",
       "      <td>09864</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>嗯</td>\n",
       "      <td>0.550</td>\n",
       "      <td>zh</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9865</th>\n",
       "      <td>09865</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>her intellect intelli</td>\n",
       "      <td>1.485</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9866</th>\n",
       "      <td>09866</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...</td>\n",
       "      <td>14.506</td>\n",
       "      <td>mixed</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9867</th>\n",
       "      <td>09867</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>home school education can provide an environme...</td>\n",
       "      <td>8.611</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9868</th>\n",
       "      <td>09868</td>\n",
       "      <td>/Users/gauravbelani/.cache/huggingface/dataset...</td>\n",
       "      <td>{'path': '/Users/gauravbelani/.cache/huggingfa...</td>\n",
       "      <td>home school</td>\n",
       "      <td>0.399</td>\n",
       "      <td>en</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9869 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               path  \\\n",
       "0     00000  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "1     00001  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "2     00002  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "3     00003  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "4     00004  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "...     ...                                                ...   \n",
       "9864  09864  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "9865  09865  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "9866  09866  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "9867  09867  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "9868  09868  /Users/gauravbelani/.cache/huggingface/dataset...   \n",
       "\n",
       "                                                  audio  \\\n",
       "0     {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "1     {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "2     {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "3     {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "4     {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "...                                                 ...   \n",
       "9864  {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "9865  {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "9866  {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "9867  {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "9868  {'path': '/Users/gauravbelani/.cache/huggingfa...   \n",
       "\n",
       "                                          transcription  duration language  \\\n",
       "0                                           我刚刚开始record     1.560    mixed   \n",
       "1                                         嗯hello我的名字叫徐妍     4.160    mixed   \n",
       "2                                嗯初次见面nice to meet you嗯     3.320    mixed   \n",
       "3                       今天呢我非常希望能够通过这个机会去跟你make friends     5.700    mixed   \n",
       "4                                                嗯你知道就是     2.020       zh   \n",
       "...                                                 ...       ...      ...   \n",
       "9864                                                  嗯     0.550       zh   \n",
       "9865                              her intellect intelli     1.485       en   \n",
       "9866  学术方面的话 其实国内也有很多 学术很厉害 的 嗯 professor之类的 但是可能整体的...    14.506    mixed   \n",
       "9867  home school education can provide an environme...     8.611       en   \n",
       "9868                                        home school     0.399       en   \n",
       "\n",
       "      original_speaker_id  session_id       topic  \n",
       "0                       1           1     persona  \n",
       "1                       1           1     persona  \n",
       "2                       1           1     persona  \n",
       "3                       1           1     persona  \n",
       "4                       1           1     persona  \n",
       "...                   ...         ...         ...  \n",
       "9864                    8           4  technology  \n",
       "9865                    8           3   education  \n",
       "9866                    8           3   education  \n",
       "9867                    8           3   education  \n",
       "9868                    8           3   education  \n",
       "\n",
       "[9869 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.DataFrame(ds[\"train\"])\n",
    "display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gauravbelani/.cache/huggingface/datasets/downloads/extracted/0f1eb62f6b2fda40ed53200130efd18d8a36f6d9269942607f6177a965da02ae/waves/ses1_spk11_L2474_312.620_9.120.wav\n",
      "<pydub.audio_segment.AudioSegment object at 0x287aaf0d0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='second_half.wav'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.at[1069, 'path'])\n",
    "my_wav = train.at[1069, 'path']\n",
    "audio = AudioSegment.from_wav(my_wav)\n",
    "print(audio)\n",
    "splitpoint = len(audio)//2\n",
    "first_half = audio[:splitpoint]\n",
    "second_half = audio[splitpoint:]\n",
    "first_half.export(\"first_half.wav\", format=\"wav\")\n",
    "second_half.export(\"second_half.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai-whisper) (0.58.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai-whisper) (1.24.3)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai-whisper) (2.0.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openai-whisper) (4.66.1)\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Obtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\n",
      "  Downloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/fb/2a/3d02ef030f387c373acbeca6d5a2307405a1da735285ec12a9ed0b6302ea/tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from numba->openai-whisper) (0.41.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
      "  Obtaining dependency information for regex>=2022.1.18 from https://files.pythonhosted.org/packages/4d/d3/38b09813a32618acd437906c4d0194119e27139dbcd7486e69d58e375a27/regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->openai-whisper) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->openai-whisper) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch->openai-whisper) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from torch->openai-whisper) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/gauravbelani/Library/Python/3.11/lib/python/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "Downloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.5.1-cp311-cp311-macosx_11_0_arm64.whl (924 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.4/924.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp311-cp311-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801344 sha256=53aff4dab1978d587dbc77f9254c4a5dfac724442230567cf82b34feeef6594d\n",
      "  Stored in directory: /Users/gauravbelani/Library/Caches/pip/wheels/55/5d/42/c296ab046d52caa0adc0e3f159e98f011b3994a022d6282105\n",
      "Successfully built openai-whisper\n",
      "Installing collected packages: regex, more-itertools, tiktoken, openai-whisper\n",
      "Successfully installed more-itertools-10.1.0 openai-whisper-20231117 regex-2023.10.3 tiktoken-0.5.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install openai-whisper\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:45<00:00, 3.18MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base\")  # Choose the appropriate model size\n",
    "def get_language_probability(audio_path):\n",
    "    \"\"\"\n",
    "    This function uses Whisper to predict the language and its probability\n",
    "    for a given audio clip.\n",
    "    \"\"\"\n",
    "    result = model.transcribe(audio_path)\n",
    "    languages = result[\"language\"]\n",
    "    # Assuming 'zh' is the code for Chinese\n",
    "    chinese_probability = languages.get('zh', 0)\n",
    "    return chinese_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mffmpeg\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(get_language_probability(my_wav))\n",
      "\u001b[1;32m/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m languages \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mlanguage\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Assuming 'zh' is the code for Chinese\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m chinese_probability \u001b[39m=\u001b[39m languages\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39m\u001b[39mzh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gauravbelani/Desktop/VSCode/DataScienceLab/FinalProject/openaitest.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m chinese_probability\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "import ffmpeg\n",
    "print(get_language_probability(my_wav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'zh', 'value': 0.9799577593803406}, {'key': 'ko', 'value': 0.011395984329283237}, {'key': 'en', 'value': 0.005589699372649193}, {'key': 'ja', 'value': 0.001790897804312408}, {'key': 'ru', 'value': 0.0002021906984737143}, {'key': 'th', 'value': 0.00016350089572370052}, {'key': 'fr', 'value': 0.00013140999362803996}, {'key': 'jw', 'value': 8.907345909392461e-05}, {'key': 'vi', 'value': 6.955331627978012e-05}, {'key': 'de', 'value': 5.6552646128693596e-05}, {'key': 'nn', 'value': 4.964123945683241e-05}, {'key': 'pl', 'value': 4.6791730710538104e-05}, {'key': 'ms', 'value': 4.432125570019707e-05}, {'key': 'pt', 'value': 3.788392132264562e-05}, {'key': 'cy', 'value': 3.445214679231867e-05}, {'key': 'ar', 'value': 3.178669430781156e-05}, {'key': 'la', 'value': 2.9656755941687152e-05}, {'key': 'it', 'value': 2.692766793188639e-05}, {'key': 'id', 'value': 2.3036496713757515e-05}, {'key': 'tr', 'value': 2.2467067537945695e-05}, {'key': 'es', 'value': 2.1060797735117376e-05}, {'key': 'haw', 'value': 2.105740350089036e-05}, {'key': 'my', 'value': 2.014956953644287e-05}, {'key': 'bo', 'value': 1.991341559914872e-05}, {'key': 'km', 'value': 1.5359568351414055e-05}, {'key': 'be', 'value': 1.5083790458447766e-05}, {'key': 'mi', 'value': 1.3789146578346845e-05}, {'key': 'nl', 'value': 9.290053640143014e-06}, {'key': 'ur', 'value': 7.757113053230569e-06}, {'key': 'br', 'value': 7.3014007284655236e-06}, {'key': 'ta', 'value': 6.866152034490369e-06}, {'key': 'hi', 'value': 5.763057743024547e-06}, {'key': 'sv', 'value': 5.1340671234356705e-06}, {'key': 'sn', 'value': 4.69496762889321e-06}, {'key': 'el', 'value': 2.9343336791498587e-06}, {'key': 'ca', 'value': 2.7662820230034413e-06}, {'key': 'si', 'value': 2.4237001525762025e-06}, {'key': 'tl', 'value': 2.196071818616474e-06}, {'key': 'fi', 'value': 1.9111835172225256e-06}, {'key': 'ht', 'value': 1.5005559816927416e-06}, {'key': 'no', 'value': 1.4987539316280163e-06}, {'key': 'uk', 'value': 1.4770229199712048e-06}, {'key': 'da', 'value': 1.2382331533444813e-06}, {'key': 'gl', 'value': 1.1499380434543127e-06}, {'key': 'eu', 'value': 9.992131708713714e-07}, {'key': 'mn', 'value': 9.383095402881736e-07}, {'key': 'sa', 'value': 9.001742569125781e-07}, {'key': 'kk', 'value': 8.828551472106483e-07}, {'key': 'lo', 'value': 8.825705890558311e-07}, {'key': 'te', 'value': 7.183525667642243e-07}, {'key': 'fa', 'value': 7.089895461831475e-07}, {'key': 'az', 'value': 6.709813078487059e-07}, {'key': 'he', 'value': 6.286429652391234e-07}, {'key': 'yo', 'value': 6.114705115578545e-07}, {'key': 'bs', 'value': 5.899913162465964e-07}, {'key': 'sw', 'value': 5.454841698337987e-07}, {'key': 'ro', 'value': 5.373899512051139e-07}, {'key': 'ml', 'value': 5.12957683440618e-07}, {'key': 'yi', 'value': 4.563580091598851e-07}, {'key': 'oc', 'value': 4.1783656001825875e-07}, {'key': 'bn', 'value': 3.504030416934256e-07}, {'key': 'cs', 'value': 3.4104905921594764e-07}, {'key': 'sl', 'value': 3.119085647540487e-07}, {'key': 'hu', 'value': 3.051886210414523e-07}, {'key': 'ne', 'value': 2.0921207521951146e-07}, {'key': 'hr', 'value': 2.0355476237909897e-07}, {'key': 'is', 'value': 1.9939636786148185e-07}, {'key': 'sk', 'value': 1.3979230573113455e-07}, {'key': 'fo', 'value': 1.343565827482962e-07}, {'key': 'bg', 'value': 1.2463503651360952e-07}, {'key': 'hy', 'value': 1.2048690223309677e-07}, {'key': 'sr', 'value': 1.0922592252882168e-07}, {'key': 'pa', 'value': 7.954430003564994e-08}, {'key': 'lv', 'value': 6.36642738527371e-08}, {'key': 'af', 'value': 6.072037450621792e-08}, {'key': 'ps', 'value': 5.0871950207920236e-08}, {'key': 'lt', 'value': 4.841401235466947e-08}, {'key': 'sd', 'value': 4.700759959064271e-08}, {'key': 'et', 'value': 3.8578040317815976e-08}, {'key': 'kn', 'value': 3.530914938210117e-08}, {'key': 'ln', 'value': 3.221306243972322e-08}, {'key': 'as', 'value': 2.3141515370639354e-08}, {'key': 'sq', 'value': 2.075971217152528e-08}, {'key': 'mt', 'value': 1.917814884677682e-08}, {'key': 'ka', 'value': 1.5482166659808172e-08}, {'key': 'am', 'value': 1.0594230381855141e-08}, {'key': 'mk', 'value': 1.0466351341165137e-08}, {'key': 'mr', 'value': 9.737270545429055e-09}, {'key': 'gu', 'value': 7.590614359287429e-09}, {'key': 'so', 'value': 7.25118454170115e-09}, {'key': 'tt', 'value': 3.476197996121755e-09}, {'key': 'lb', 'value': 3.0836495579222856e-09}, {'key': 'tg', 'value': 2.7728257467884987e-09}, {'key': 'su', 'value': 1.929286508328687e-09}, {'key': 'ha', 'value': 5.056273177928006e-10}, {'key': 'ba', 'value': 4.673827436185718e-10}, {'key': 'uz', 'value': 4.603455672214096e-10}, {'key': 'tk', 'value': 3.5873293224852887e-10}, {'key': 'mg', 'value': 1.9131182749099196e-10}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zh_en_probs(file):\n",
    "    model = whisper.load_model(\"base\")\n",
    "    thisaudio = whisper.load_audio(file)\n",
    "    thisaudio = whisper.pad_or_trim(thisaudio)\n",
    "    mel = whisper.log_mel_spectrogram(thisaudio).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "\n",
    "    # Sorting the dictionary items by values in descending order\n",
    "    sorted_probs = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Creating a new list with the sorted key-value pairs\n",
    "    sorted_probs = [{'key': key, 'value': value} for key, value in sorted_probs]\n",
    "\n",
    "    \n",
    "    zh_prob = probs[\"zh\"]\n",
    "    en_prob = probs[\"en\"]\n",
    "\n",
    "    return (zh_prob, en_prob)\n",
    "\n",
    "\n",
    "    # print(probs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole file chinese prob, english prob: (0.4901089668273926, 0.14796403050422668)\n",
      "clip_0 chinese prob, english prob: (0.7450914978981018, 0.11018414050340652)\n",
      "clip_1 chinese prob, english prob: (0.03820514678955078, 0.5197636485099792)\n"
     ]
    }
   ],
   "source": [
    "my_file = train.at[2, 'path']\n",
    "audio = AudioSegment.from_wav(my_file)\n",
    "\n",
    "print(f\"Whole file chinese prob, english prob: {get_zh_en_probs(my_file)}\")\n",
    "\n",
    "clip_duration = 2000\n",
    "# Initialize the start time\n",
    "start_time = 0\n",
    "\n",
    "# Split and export each clip\n",
    "clip_index = 0\n",
    "while start_time < len(audio):\n",
    "    # Calculate the end time, but don't exceed the length of the audio\n",
    "    end_time = min(start_time + clip_duration, len(audio))\n",
    "\n",
    "    # Extract and export the clip\n",
    "    clip = audio[start_time:end_time]\n",
    "    clip.export(f\"clip_{clip_index}.wav\", format=\"wav\")\n",
    "\n",
    "    #Get lang prob for this clip\n",
    "    print(f\"clip_{clip_index} chinese prob, english prob: {get_zh_en_probs(f'clip_{clip_index}.wav')}\")\n",
    "\n",
    "    # Move to the next clip\n",
    "    start_time += clip_duration\n",
    "    clip_index += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
